#!/usr/bin/env python3
"""
× ×™×ª×•×— ×œ×•×’×™× × ×§×™×™× - Clean Logs Analyzer
=========================================

×¡×§×¨×™×¤×˜ ×œ× ×™×ª×•×— ×”×œ×•×’×™× ×”× ×§×™×™× ×•×”×¦×’×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ××¢× ×™×™× ×•×ª.

Usage:
    python analyze_clean_logs.py
"""

import os
import re
from pathlib import Path
from datetime import datetime
from collections import Counter
from typing import Dict, List, Tuple


class CleanLogsAnalyzer:
    """
    ×× ×ª×— ×œ×•×’×™× × ×§×™×™×
    """
    
    def __init__(self, log_dir: str = "clean_logs"):
        self.log_dir = Path(log_dir)
        self.conversations = []
    
    def load_logs(self):
        """
        ×˜×¢×™× ×ª ×›×œ ×§×‘×¦×™ ×”×œ×•×’
        """
        if not self.log_dir.exists():
            print(f"âŒ ×ª×™×§×™×™×” ×œ× ×§×™×™××ª: {self.log_dir}")
            return
        
        log_files = sorted(self.log_dir.glob("conversation_*.log"))
        
        if not log_files:
            print("âš ï¸  ×œ× × ××¦××• ×§×‘×¦×™ ×œ×•×’")
            return
        
        print(f"ğŸ“‚ ×§×•×¨× {len(log_files)} ×§×‘×¦×™ ×œ×•×’...")
        
        for log_file in log_files:
            self._parse_log_file(log_file)
        
        print(f"âœ… × ×˜×¢× ×• {len(self.conversations)} ×©×™×—×•×ª\n")
    
    def _parse_log_file(self, log_file: Path):
        """
        ×¤×¢× ×•×— ×§×•×‘×¥ ×œ×•×’ ×‘×•×“×“
        """
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ×—×™×¤×•×© ×›×œ ×”×©×™×—×•×ª
        pattern = r'\[([^\]]+)\](?:\s+Task ID: ([^\n]+))?\s+ğŸ“¤ PROMPT:\s+([^\n]+(?:\n(?!ğŸ“¥)[^\n]+)*)\s+ğŸ“¥ RESPONSE:\s+([^\n]+(?:\n(?!=====)[^\n]+)*)'
        
        matches = re.finditer(pattern, content, re.MULTILINE)
        
        for match in matches:
            timestamp_str, task_id, prompt, response = match.groups()
            
            try:
                timestamp = datetime.strptime(timestamp_str.strip(), "%Y-%m-%d %H:%M:%S")
            except:
                timestamp = None
            
            self.conversations.append({
                'timestamp': timestamp,
                'task_id': task_id.strip() if task_id else None,
                'prompt': prompt.strip(),
                'response': response.strip()
            })
    
    def analyze(self):
        """
        × ×™×ª×•×— ×”×œ×•×’×™×
        """
        if not self.conversations:
            print("âŒ ××™×Ÿ ×©×™×—×•×ª ×œ× ×™×ª×•×—")
            return
        
        print("="*70)
        print("ğŸ“Š × ×™×ª×•×— ×œ×•×’×™× × ×§×™×™×")
        print("="*70)
        print()
        
        self._general_stats()
        self._temporal_analysis()
        self._response_types_analysis()
        self._prompt_analysis()
    
    def _general_stats(self):
        """
        ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª
        """
        print("ğŸ“ˆ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª:")
        print("-" * 70)
        print(f"   ×¡×”\"×› ×©×™×—×•×ª: {len(self.conversations)}")
        
        # ×ª××¨×™×›×™×
        timestamps = [c['timestamp'] for c in self.conversations if c['timestamp']]
        if timestamps:
            first_date = min(timestamps).strftime("%Y-%m-%d")
            last_date = max(timestamps).strftime("%Y-%m-%d")
            print(f"   ×ª×§×•×¤×”: {first_date} - {last_date}")
        
        # ××•×¨×›×™ ×¤×¨×•××¤×˜×™×
        prompt_lengths = [len(c['prompt']) for c in self.conversations]
        avg_prompt_length = sum(prompt_lengths) / len(prompt_lengths)
        print(f"   ××•×¨×š ×¤×¨×•××¤×˜ ×××•×¦×¢: {avg_prompt_length:.0f} ×ª×•×•×™×")
        
        # ××•×¨×›×™ ×ª×©×•×‘×•×ª
        response_lengths = [len(c['response']) for c in self.conversations]
        avg_response_length = sum(response_lengths) / len(response_lengths)
        print(f"   ××•×¨×š ×ª×©×•×‘×” ×××•×¦×¢: {avg_response_length:.0f} ×ª×•×•×™×")
        print()
    
    def _temporal_analysis(self):
        """
        × ×™×ª×•×— ×–×× ×™
        """
        print("â° × ×™×ª×•×— ×–×× ×™:")
        print("-" * 70)
        
        timestamps = [c['timestamp'] for c in self.conversations if c['timestamp']]
        if not timestamps:
            print("   ××™×Ÿ × ×ª×•× ×™ ×–××Ÿ ×–××™× ×™×\n")
            return
        
        # ×©×™×—×•×ª ×œ×¤×™ ×ª××¨×™×š
        dates = [t.date() for t in timestamps]
        date_counter = Counter(dates)
        
        print("   ×©×™×—×•×ª ×œ×¤×™ ×™×•×:")
        for date, count in sorted(date_counter.items()):
            print(f"      {date}: {'â–ˆ' * count} {count}")
        
        # ×©×™×—×•×ª ×œ×¤×™ ×©×¢×”
        hours = [t.hour for t in timestamps]
        hour_counter = Counter(hours)
        
        print("\n   ×©×™×—×•×ª ×œ×¤×™ ×©×¢×”:")
        for hour in range(24):
            count = hour_counter.get(hour, 0)
            if count > 0:
                bar = 'â–ˆ' * (count // 2 if count > 10 else count)
                print(f"      {hour:02d}:00 - {hour:02d}:59: {bar} {count}")
        print()
    
    def _response_types_analysis(self):
        """
        × ×™×ª×•×— ×¡×•×’×™ ×ª×©×•×‘×•×ª
        """
        print("ğŸ¯ ×¡×•×’×™ ×ª×©×•×‘×•×ª:")
        print("-" * 70)
        
        # ×—×™×¤×•×© ×××•×’'×™ ×‘×ª×©×•×‘×•×ª
        emojis = []
        for conv in self.conversations:
            response = conv['response']
            # ×—×™×¤×•×© ×××•×’'×™ × ×¤×•×¦×™×
            if 'âœ‰ï¸' in response or '××™×™×œ' in response.lower():
                emojis.append('âœ‰ï¸ Email')
            elif 'ğŸ“Š' in response or '×“×•×—' in response.lower():
                emojis.append('ğŸ“Š Report')
            elif 'ğŸ’¾' in response or '×’×™×‘×•×™' in response.lower():
                emojis.append('ğŸ’¾ Backup')
            elif 'ğŸ”„' in response or '×¢×“×›×•×Ÿ' in response.lower():
                emojis.append('ğŸ”„ Update')
            elif 'âœ…' in response:
                emojis.append('âœ… Success')
            else:
                emojis.append('â“ Other')
        
        emoji_counter = Counter(emojis)
        
        for emoji_type, count in emoji_counter.most_common():
            percentage = (count / len(self.conversations)) * 100
            bar = 'â–ˆ' * int(percentage / 5)
            print(f"   {emoji_type:15} {bar} {count} ({percentage:.1f}%)")
        print()
    
    def _prompt_analysis(self):
        """
        × ×™×ª×•×— ×¤×¨×•××¤×˜×™×
        """
        print("ğŸ’¬ × ×™×ª×•×— ×¤×¨×•××¤×˜×™×:")
        print("-" * 70)
        
        # ××™×œ×•×ª ××¤×ª×— × ×¤×•×¦×•×ª
        all_prompts = ' '.join([c['prompt'].lower() for c in self.conversations])
        
        # ×¡×¤×™×¨×ª ××™×œ×™× × ×¤×•×¦×•×ª (×¢×‘×¨×™×ª ×•×× ×’×œ×™×ª)
        keywords = ['××™×™×œ', 'email', '×“×•×—', 'report', '×¢×“×›×Ÿ', 'update', 
                   '×’×™×‘×•×™', 'backup', '×©×œ×—', 'send', '×¦×•×¨', 'create',
                   '×‘×“×•×§', 'check', '× ×ª×—', 'analyze']
        
        keyword_counts = {}
        for keyword in keywords:
            count = all_prompts.count(keyword)
            if count > 0:
                keyword_counts[keyword] = count
        
        if keyword_counts:
            print("   ××™×œ×•×ª ××¤×ª×— × ×¤×•×¦×•×ª:")
            for keyword, count in sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"      {keyword:15} {count} ×¤×¢××™×")
        
        print()
        
        # ×”×¤×¨×•××¤×˜×™× ×”××¨×•×›×™× ×‘×™×•×ª×¨
        print("   ×”×¤×¨×•××¤×˜×™× ×”××¨×•×›×™× ×‘×™×•×ª×¨:")
        sorted_by_length = sorted(self.conversations, key=lambda x: len(x['prompt']), reverse=True)
        for i, conv in enumerate(sorted_by_length[:3], 1):
            prompt_preview = conv['prompt'][:60] + "..." if len(conv['prompt']) > 60 else conv['prompt']
            print(f"      {i}. ({len(conv['prompt'])} ×ª×•×•×™×) {prompt_preview}")
        print()
    
    def export_summary(self, output_file: str = "logs_summary.txt"):
        """
        ×™×™×¦×•× ×¡×™×›×•× ×œ×§×•×‘×¥
        """
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("ğŸ“Š ×¡×™×›×•× × ×™×ª×•×— ×œ×•×’×™× × ×§×™×™×\n")
            f.write("="*70 + "\n\n")
            
            f.write(f"× ×•×¦×¨: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"×¡×”\"×› ×©×™×—×•×ª: {len(self.conversations)}\n\n")
            
            f.write("×©×™×—×•×ª ××—×¨×•× ×•×ª:\n")
            f.write("-"*70 + "\n")
            for conv in self.conversations[-10:]:
                f.write(f"\n[{conv['timestamp']}]\n")
                f.write(f"Prompt: {conv['prompt'][:100]}...\n")
                f.write(f"Response: {conv['response'][:100]}...\n")
        
        print(f"âœ… ×¡×™×›×•× ×™×•×¦× ×œ: {output_file}")


def main():
    """
    × ×§×•×“×ª ×›× ×™×¡×” ×¨××©×™×ª
    """
    analyzer = CleanLogsAnalyzer()
    analyzer.load_logs()
    
    if analyzer.conversations:
        analyzer.analyze()
        
        # ×©××œ×” ×× ×œ×™×™×¦×
        try:
            export = input("\n×œ×™×™×¦× ×¡×™×›×•× ×œ×§×•×‘×¥? (y/n): ").lower()
            if export == 'y':
                analyzer.export_summary()
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ×‘×™×™!")


if __name__ == "__main__":
    main()
